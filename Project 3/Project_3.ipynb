{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907dc0ee",
   "metadata": {},
   "source": [
    "### Cameron Stewart\n",
    "# Project 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f01cc48f",
   "metadata": {},
   "source": [
    "### 1.\tCompare your given name with your nickname (if you donâ€™t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "*   What is the edit distance between your nickname and your given name?\n",
    "*\tWhat is the percentage string match between your nickname and your given name?\n",
    "*   Show your work for both calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48efecd7",
   "metadata": {},
   "source": [
    "First, I found the edit distance between my name and nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f954277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba78b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Name: Cameron\n",
      "Nickname Camo\n",
      "Edit Distance: 3\n",
      "Edit Steps: 'Cameron'->'Camero'->'Cameo'->'Camo'\n"
     ]
    }
   ],
   "source": [
    "#Names to compare\n",
    "given_name='Cameron'\n",
    "nickname='Camo'\n",
    "\n",
    "#Levenshtein edit distance between given and nickname\n",
    "edit_distance=nltk.edit_distance(given_name,nickname)\n",
    "print('Given Name:',given_name)\n",
    "print('Nickname',nickname)\n",
    "print('Edit Distance:',edit_distance)\n",
    "print(\"Edit Steps: 'Cameron'->'Camero'->'Cameo'->'Camo'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ac5d2",
   "metadata": {},
   "source": [
    "Next, I found the percentage string match between my name and nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfaf9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa75f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Name: Cameron\n",
      "Nickname: Camo\n",
      "Edit Steps: 'Cameron'->'Camero'->'Cameo'->'Camo'\n",
      "String Match Percentage = 1-(edit distance/length of longer string)\n",
      "String Match Percentage = 1-(3/7)\n",
      "String Match Percentage: 57.14%\n"
     ]
    }
   ],
   "source": [
    "#Names to compare\n",
    "given_name='Cameron'\n",
    "nickname='Camo'\n",
    "\n",
    "#String match between given and nickname\n",
    "edit_distance=nltk.edit_distance(given_name,nickname)\n",
    "string_match_perc=textdistance.levenshtein.normalized_similarity(given_name,nickname)\n",
    "print('Given Name:',given_name)\n",
    "print('Nickname:',nickname)\n",
    "print(\"Edit Steps: 'Cameron'->'Camero'->'Cameo'->'Camo'\")\n",
    "print(\"String Match Percentage = 1-(edit distance/length of longer string)\")\n",
    "print(\"String Match Percentage = 1-(\",edit_distance,\"/\",max(len(given_name),len(nickname)),\")\",sep=\"\")\n",
    "print('String Match Percentage: ',round(string_match_perc*100,2),\"%\",sep=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5fc5f72",
   "metadata": {},
   "source": [
    "### 2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5c81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf764440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: ['when', 'i', 'think', 'of', 'my', 'wife', ',', 'i', 'always', 'think', 'of', 'her', 'head', '.', 'the', 'shape', 'of', 'it', ',', 'to', 'begin', 'with', '.']\n",
      "Opening Text With Stop Words Removed: ['think', 'wife', ',', 'always', 'think', 'head', '.', 'shape', ',', 'begin', '.']\n"
     ]
    }
   ],
   "source": [
    "#Storing and tokenizing opening text\n",
    "opening_text=\"When I think of my wife, I always think of her head. The shape of it, to begin with.\"\n",
    "opening_text=opening_text.lower()\n",
    "tokenized_text=nltk.word_tokenize(opening_text)\n",
    "\n",
    "#Remove stop words and compare\n",
    "tokenized_text_stop_removed=[x for x in tokenized_text if x not in stopwords.words('english')]\n",
    "print('Original Text:',tokenized_text)\n",
    "print('Opening Text With Stop Words Removed:', tokenized_text_stop_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1679736",
   "metadata": {},
   "source": [
    "The book selected to parse out the stop words was 'Gone Girl' by Gillian Flynn. The book guessed was Every Breath You Take: A True Story of Obsession, Revenge, and Murder by Ann Rule. After a few more guesses and light hinting, she was able to guess the correct book. I don't believe she was able to guess the correct book because she reads many murder mystery books and the first few sentences are not that specific. The interesting takeaway was how much insight she was able to obtain from such a small amount of information. She had a sense it was a murder mystery genre novel about a husband and wife from just 7 words. I imagine with a few more sentences that she would have been able to correctly guess on the first attempt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857bf2ae",
   "metadata": {},
   "source": [
    "### 3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8150e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a1245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Opening Text With Porter Stemmer: ['when', 'i', 'think', 'of', 'my', 'wife', 'i', 'alway', 'think', 'of', 'her', 'head', 'the', 'shape', 'of', 'it', 'to', 'begin', 'with']\n",
      "Lemmatized Opening Text With WordNet Lemmatizer: ['when', 'i', 'think', 'of', 'my', 'wife', 'i', 'always', 'think', 'of', 'her', 'head', 'the', 'shape', 'of', 'it', 'to', 'begin', 'with']\n",
      "Valid Morphological Root Percentage WITH Stop Words: 94.74%\n",
      "Valid Morphological Root Percentage WITHOUT Stop Words: 85.71%\n"
     ]
    }
   ],
   "source": [
    "#Storing and tokenizing opening text\n",
    "opening_text=\"When I think of my wife, I always think of her head. The shape of it, to begin with.\"\n",
    "opening_text=opening_text.lower()\n",
    "tokenized_text=nltk.word_tokenize(opening_text)\n",
    "\n",
    "#Remove stop words\n",
    "tokenized_text_stop_removed=[x for x in tokenized_text if x not in stopwords.words('english')]\n",
    "\n",
    "#Stem the non-punctuation tokens\n",
    "stemmed_words_w_sw=[nltk.PorterStemmer().stem(word) for word in tokenized_text if word not in string.punctuation]\n",
    "stemmed_words_wo_sw=[nltk.PorterStemmer().stem(word) for word in tokenized_text_stop_removed if word not in string.punctuation]\n",
    "print('Stemmed Opening Text With Porter Stemmer:',stemmed_words_w_sw)\n",
    "\n",
    "#We will find the morphological root using lemmatization on the non-punctuation tokens\n",
    "lemmatized_words_w_sw=[nltk.WordNetLemmatizer().lemmatize(word) for word in tokenized_text if word not in string.punctuation]\n",
    "lemmatized_words_wo_sw=[nltk.WordNetLemmatizer().lemmatize(word) for word in tokenized_text_stop_removed if word not in string.punctuation]\n",
    "print('Lemmatized Opening Text With WordNet Lemmatizer:',lemmatized_words_w_sw)\n",
    "\n",
    "#Find the percentage of stems that are valid morphological roots\n",
    "morph_root_percentage_w_sw=sum([lemmatized_words_w_sw[x]==stemmed_words_w_sw[x] for x in range(len(lemmatized_words_w_sw))])/len(lemmatized_words_w_sw)\n",
    "morph_root_percentage_wo_sw=sum([lemmatized_words_wo_sw[x]==stemmed_words_wo_sw[x] for x in range(len(lemmatized_words_wo_sw))])/len(lemmatized_words_wo_sw)\n",
    "print('Valid Morphological Root Percentage WITH Stop Words: ',round(morph_root_percentage_w_sw*100,2),'%',sep=\"\")\n",
    "print('Valid Morphological Root Percentage WITHOUT Stop Words: ',round(morph_root_percentage_wo_sw*100,2),'%',sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732e1a1",
   "metadata": {},
   "source": [
    "I made the assumption to remove punctuation as tokens in this analysis of stemming and valid morphological root words. I used the Porter Stemmer to find the stem of each word. I used the WordNet Lemmatizer to find the valid mophological root of each word. After comparing these two transformations of the text, the only word that is different is the 'alway' stem and 'always' lemma. This one difference resulted in a 94.74% success rate of the stemmer finding a valid morphological root. This value significantly changes to 85.71% if you remove the stop words."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98188f228320b9c11c456464a36d308a8574f056afe4f13f0d58da7d046c4bd7"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ds_p37_r35]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
